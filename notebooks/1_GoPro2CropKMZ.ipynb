{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJYsgRYq9tQR"
      },
      "source": [
        "# GoPro Photos to Crop KMZ\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/nasaharvest/helmets-kenya/blob/main/notebooks/1_GoPro2CropKMZ.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "**Author**: Ivan Zvonkov\n",
        "\n",
        "**Last Modified**: Jan 23, 2025\n",
        "\n",
        "**Description**: Converts GoPro photos to crop type points. Specifically the notebook:\n",
        "\n",
        "1. Downloads GoPro photos from Google Cloud or Google Drive.\n",
        "2. Create a dataframe from photos.\n",
        "3. Extract dates and coordinates.\n",
        "4. Move coordinate to field\n",
        "5. Classify as crop or not crop.\n",
        "6. Segment crops in crop photos.\n",
        "7. Filter out low confidence predictions.\n",
        "8. Get Admin Zones for each point\n",
        "9. Create KMZ file\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vsz6lpeBDfO"
      },
      "source": [
        "## Important Prerequisite\n",
        "\n",
        "Before running any cell in the notebook,\n",
        "1. Click the drop down triangle on the top right hand side and select \"Change Runtime Type\".\n",
        "2. Click the T4 radio button under Hardware Accelerator and click save.\n",
        "\n",
        "This will allow the CropSegmentation model to run much faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HooUu8spC4an"
      },
      "outputs": [],
      "source": [
        "# Required packages\n",
        "!pip install exifread utm simplekml -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bInVS3VT96L3"
      },
      "source": [
        "## 1. Download GoPro photos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JHBb5NTrWbA"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Login to Google Cloud, once you run this cell click on the space after \"browser:\" to enter the code\n",
        "!gcloud auth login\n",
        "# Your current project will be [None] and that is okay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TE5T13gVMLa7"
      },
      "outputs": [],
      "source": [
        "print(\"Select Location of GoPro Photos\")\n",
        "print(\"1. Google Cloud Storage (Preferred)\")\n",
        "print(\"2. Google Drive\")\n",
        "selection = input(\"Enter selection [ 1 / 2 ]: \")\n",
        "\n",
        "#########################################\n",
        "# Download GoPros from Google Cloud\n",
        "#########################################\n",
        "GCLOUD_PATH_INPUT = \"\"\n",
        "if selection == \"1\":\n",
        "\n",
        "    print(\"\\nCopy and paste the path of the Google Cloud Storage folder with GoPro Photos\")\n",
        "    print(\"(Example: street2sat-uploaded/KENYA_v2/2021_07_13_T2/100GOPRO)\")\n",
        "    GCLOUD_PATH_INPUT = input(\"Path: \")\n",
        "\n",
        "    GCLOUD_PATH = f\"gs://{GCLOUD_PATH_INPUT}/*\"\n",
        "    PREFIX = GCLOUD_PATH_INPUT.replace(\"street2sat-uploaded/\", \"\").replace(\"/\", \"_\")\n",
        "    Path(PREFIX).mkdir(exist_ok=True)\n",
        "    print(f\"\\nReady to download images from \\n{GCLOUD_PATH} to {PREFIX}\")\n",
        "\n",
        "    # Check amount of photos\n",
        "    !gsutil du $GCLOUD_PATH | wc -l\n",
        "\n",
        "    confirm = input(\"Confirm? [y/n]: \")\n",
        "    if confirm == \"y\":\n",
        "        # 20 mins for 10k images\n",
        "        !gsutil -m cp -r $GCLOUD_PATH $PREFIX\n",
        "    else:\n",
        "        raise print(\"Cancelled\")\n",
        "\n",
        "#########################################\n",
        "# Download GoPros from Google Drive\n",
        "#########################################\n",
        "elif selection == \"2\":\n",
        "    print(\"\\nPath of Google Drive Folder with photos:\")\n",
        "    print(\"(Example: /content/drive/MyDrive/2021-07-05-T1)\")\n",
        "    PREFIX = input(\"\").replace(\"/content/\", \"\")\n",
        "\n",
        "else:\n",
        "    raise ValueError(f\"Invalid selection: '{selection}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXHDUZr-XygC"
      },
      "outputs": [],
      "source": [
        "country_is_right_hand_drive = {\n",
        "    \"KENYA\": False,\n",
        "    \"MADAGASCAR\": True\n",
        "}\n",
        "\n",
        "# If country not in prefix, \"is_right_hand_drive\" has to be set manually\n",
        "is_right_hand_drive = None\n",
        "\n",
        "for country, is_rhs in country_is_right_hand_drive.items():\n",
        "    if country in PREFIX.upper():\n",
        "        is_right_hand_drive = is_rhs\n",
        "        break\n",
        "\n",
        "\n",
        "assert is_right_hand_drive != None, \"Drive direction not derived, set 'is_right_hand_drive' manually\"\n",
        "print(\"Assuming \" + (\"right hand drive\" if is_right_hand_drive else \"left hand drive for:\"))\n",
        "print(PREFIX)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjomcjvh_GJQ"
      },
      "source": [
        "## 2. Create dataframe from available photos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejFpnepF_OhO"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from shapely.geometry import Point\n",
        "from tqdm import tqdm\n",
        "\n",
        "import exifread\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "image_folder = Path(f\"/content/{PREFIX}\")\n",
        "if (not image_folder.exists()):\n",
        "    print(\"STOP: Update image_folder to match the folder of images you downloaded\")\n",
        "else:\n",
        "    gopro_photo_paths = list(image_folder.glob(\"**/*.JPG\")) # May need to switch to .jpg\n",
        "    df = pd.DataFrame({\"paths\": gopro_photo_paths})\n",
        "\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaTYZA2q5J63"
      },
      "source": [
        "## 3. Extract date and coordinate from each available photo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2vDKktE2Rnw"
      },
      "outputs": [],
      "source": [
        "def extract_date_lat_lon(img_path):\n",
        "    img_bytes = open(img_path, \"rb\")\n",
        "    tags = exifread.process_file(img_bytes)\n",
        "\n",
        "    required_keys = [\n",
        "        \"Image DateTime\",\n",
        "        \"GPS GPSLatitude\",\n",
        "        \"GPS GPSLongitude\",\n",
        "        \"GPS GPSLatitudeRef\",\n",
        "        \"GPS GPSLongitudeRef\"\n",
        "    ]\n",
        "    if not all(key in tags for key in required_keys):\n",
        "        return None, None, None\n",
        "\n",
        "    # Extract date\n",
        "    image_datetime = str(tags[\"Image DateTime\"])\n",
        "\n",
        "    # Convert to Python datetime object\n",
        "    dt = datetime.strptime(image_datetime, \"%Y:%m:%d %H:%M:%S\")\n",
        "\n",
        "    def convert_to_degrees(coord):\n",
        "        \"\"\" Convert the GPS coordinates stored in the EXIF to degress in float format\"\"\"\n",
        "        d = float(coord.values[0].num) / float(coord.values[0].den)\n",
        "        m = float(coord.values[1].num) / float(coord.values[1].den)\n",
        "        s = float(coord.values[2].num) / float(coord.values[2].den)\n",
        "        return d + (m / 60.0) + (s / 3600.0)\n",
        "\n",
        "    lat = convert_to_degrees(tags[\"GPS GPSLatitude\"])\n",
        "    lon = convert_to_degrees(tags[\"GPS GPSLongitude\"])\n",
        "\n",
        "    if tags[\"GPS GPSLatitudeRef\"].values[0] != \"N\":\n",
        "        lat = 0 - lat\n",
        "    if tags[\"GPS GPSLongitudeRef\"].values[0] != \"E\":\n",
        "        lon = 0 - lon\n",
        "\n",
        "    return dt, lat, lon\n",
        "\n",
        "# Extract date and lat lon from each image\n",
        "df[[\"date\", \"lat\", \"lon\"]] = df[\"paths\"].progress_apply(extract_date_lat_lon).to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7zooM-x88R0"
      },
      "outputs": [],
      "source": [
        "print(f\"Total photos: {len(df)}\")\n",
        "df = df[~df[\"lon\"].isna()].copy()\n",
        "print(f\"Photos with valid exif tags: {len(df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lg2jfzW5Gb6X"
      },
      "outputs": [],
      "source": [
        "gdf = gpd.GeoDataFrame(df, geometry=[Point(xy) for xy in zip(df[\"lon\"], df[\"lat\"])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whYVHZKKpimn"
      },
      "outputs": [],
      "source": [
        "from shapely.geometry import Point\n",
        "from matplotlib.patches import Rectangle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Obtain Admin Boundaries from GADM: https://gadm.org/data.html\n",
        "gdf_gadm2 = gpd.read_file(\"https://geodata.ucdavis.edu/gadm/gadm4.1/json/gadm41_KEN_2.json\")\n",
        "\n",
        "padding = 0.05\n",
        "x_min, x_max = [df[\"lon\"].min() - padding, df[\"lon\"].max() + padding]\n",
        "y_min, y_max = [df[\"lat\"].min() - padding, df[\"lat\"].max() + padding]\n",
        "\n",
        "_, axes = plt.subplots(1, 2, figsize=(12, 10))\n",
        "for ax in axes:\n",
        "    gdf_gadm2.plot(ax=ax, facecolor=\"lightgray\", edgecolor=\"black\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "gdf.plot(ax=axes[0], color='red', markersize=1)\n",
        "gdf.plot(ax=axes[1], color='red', markersize=3)\n",
        "rect = Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, edgecolor='blue', facecolor='none')\n",
        "axes[0].add_patch(rect)\n",
        "axes[1].set_xlim([x_min, x_max]) # For zoomed in version\n",
        "axes[1].set_ylim([y_min, y_max]) # For zoomed in version\n",
        "\n",
        "for x, y, label in zip(gdf_gadm2.geometry.centroid.x, gdf_gadm2.geometry.centroid.y, gdf_gadm2['NAME_2']):\n",
        "  if x_min <= x <= x_max and y_min <= y <= y_max:\n",
        "    axes[1].text(x, y, label, fontsize=8, ha='center')\n",
        "\n",
        "axes[1].set_title(\"Zoomed In\", fontsize=15);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfYD0VtGE_6e"
      },
      "source": [
        "## 4. Move coordinate to field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2t19_SAFmw6"
      },
      "outputs": [],
      "source": [
        "import utm\n",
        "from datetime import timedelta\n",
        "import math\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIjwO4TsFlme"
      },
      "outputs": [],
      "source": [
        "# Copied and pasted from field_coord_distance_offset.ipynb\n",
        "\n",
        "floor10 = lambda x: x//10 * 10\n",
        "to_pixel_centroid = lambda coord: (floor10(coord[0]) + 5, floor10(coord[1]) + 5)\n",
        "\n",
        "def generate_offset_point_wgs84(coord0, coord1, is_right_hand_drive=True, meters=20):\n",
        "    utm_coord0 = utm.from_latlon(coord0[0], coord0[1])\n",
        "    utm_coord1 = utm.from_latlon(coord1[0], coord1[1])\n",
        "\n",
        "    for i, zone_type in [(2, \"number\"), (3, \"letter\")]:\n",
        "        if utm_coord1[i] != utm_coord0[i]:\n",
        "            print(utm_coord0)\n",
        "            print(utm_coord1)\n",
        "            raise ValueError(f\"UTM Zone {zone_type} mismatch: {utm_coord0[i]} and {utm_coord1[i]}\")\n",
        "\n",
        "\n",
        "    delta_east = utm_coord1[0] - utm_coord0[0]\n",
        "    delta_north = utm_coord1[1] - utm_coord0[1]\n",
        "\n",
        "    # Offset for meters change in offset point distance\n",
        "    x_offset = np.abs(meters * math.cos(math.atan(delta_east / delta_north)))\n",
        "\n",
        "    # Direction of offset\n",
        "    x_direction = np.sign(delta_north) if is_right_hand_drive else -np.sign(delta_north)\n",
        "    x_offset *= x_direction\n",
        "\n",
        "    orthogonal_slope = -delta_east / delta_north\n",
        "    orthogonal_b = utm_coord1[1] - (orthogonal_slope * utm_coord1[0])\n",
        "    orthogonal_y = lambda x: orthogonal_slope*x + orthogonal_b\n",
        "\n",
        "    field_point_x = utm_coord1[0] + x_offset\n",
        "    field_point_y = orthogonal_y(field_point_x)\n",
        "\n",
        "    field_latlon = utm.to_latlon(field_point_x, field_point_y, utm_coord1[2], utm_coord1[3])\n",
        "\n",
        "    pixel_centroid_x, pixel_centroid_y  = to_pixel_centroid((field_point_x, field_point_y))\n",
        "    pixel_centroid_field_latlon = utm.to_latlon(pixel_centroid_x, pixel_centroid_y, utm_coord1[2], utm_coord1[3])\n",
        "\n",
        "    return field_latlon, pixel_centroid_field_latlon, (delta_east, delta_north)\n",
        "\n",
        "def road_pixel_centroid(coord):\n",
        "    utm_coord = utm.from_latlon(coord[0], coord[1])\n",
        "    utm_pixel_centroid = to_pixel_centroid(utm_coord)\n",
        "    return utm.to_latlon(*utm_pixel_centroid, utm_coord[2], utm_coord[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNF0Z9woE-TS"
      },
      "outputs": [],
      "source": [
        "field_points = []\n",
        "meters = 20\n",
        "\n",
        "for i in tqdm(range(0, len(df))):\n",
        "\n",
        "    # Get road coordinate\n",
        "    current_record = df.iloc[i]\n",
        "    road_coord = current_record[\"lat\"], current_record[\"lon\"]\n",
        "    road_10m_centroid = road_pixel_centroid(road_coord)\n",
        "\n",
        "    # Get prior coordinate\n",
        "    time1 = current_record[\"date\"]\n",
        "    before_time_interval = time1 - timedelta(seconds=10)\n",
        "    time_filter = (df[\"date\"] < str(time1)) & (df[\"date\"] > str(before_time_interval))\n",
        "    prior_records = df[time_filter].sort_values(by=['date'])\n",
        "    if len(prior_records) == 0:\n",
        "        print(f\"No prior records found for {i}\")\n",
        "        continue\n",
        "\n",
        "    prior_record = prior_records.iloc[-1]\n",
        "    prior_coord = prior_record[\"lat\"], prior_record[\"lon\"]\n",
        "\n",
        "    # Get direction and field offset\n",
        "    try:\n",
        "        output = generate_offset_point_wgs84(prior_coord, road_coord, is_right_hand_drive, meters)\n",
        "        offset_field_coord, offset_field_pixel_centroid, driving_direction = output\n",
        "\n",
        "        field_points.append({\n",
        "            \"road_pixel_centroid\": road_10m_centroid,\n",
        "            \"is_right_hand_drive\": is_right_hand_drive,\n",
        "            \"driving_easting\": driving_direction[0],\n",
        "            \"driving_northing\": driving_direction[1],\n",
        "            \"offset_field_coord\": offset_field_coord,\n",
        "            \"offset_field_pixel_centroid\": offset_field_pixel_centroid,\n",
        "            \"time_computed\": datetime.now(),\n",
        "            **df.iloc[i],\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"Index: {i}, Exception: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGlXFH6VCzqN"
      },
      "outputs": [],
      "source": [
        "df_w_duplicates = pd.DataFrame(field_points)\n",
        "print(f\"Points BEFORE deduplicating: {len(df_w_duplicates)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXcHf7hx8Nb4"
      },
      "outputs": [],
      "source": [
        "df_clean = df_w_duplicates.drop_duplicates(subset=['offset_field_pixel_centroid']).reset_index(drop=True)\n",
        "print(f\"Points AFTER deduplicating: {len(df_clean)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABTLSIrB5uxA"
      },
      "source": [
        "## 4. Classify as crop or not crop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoZtQs26AWd2"
      },
      "outputs": [],
      "source": [
        "# Download CropNop model weights\n",
        "!gsutil cp gs://street2sat-models/cropnop_v1.torchscript.pt ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bdrloc9ELb_3"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load CropNop model\n",
        "cropnop_model = torch.jit.load(\"/content/cropnop_v1.torchscript.pt\", map_location=device)\n",
        "\n",
        "def is_crop_or_not(img_path):\n",
        "\n",
        "    # Preprocess image\n",
        "    img = plt.imread(img_path)\n",
        "    img = cv2.resize(img, (300, 300)) / 255\n",
        "    img = img.transpose(2, 0, 1).astype(\"float32\")\n",
        "    img_tensor = torch.from_numpy(img).float().to(device)\n",
        "\n",
        "    # Make crop or not prediction\n",
        "    output = cropnop_model(img_tensor.unsqueeze(0))\n",
        "    is_crop = (output <= 0).item()\n",
        "    return is_crop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZkkgjji2kUM"
      },
      "outputs": [],
      "source": [
        "# Display 9 example CropNop model predictions\n",
        "preds = [is_crop_or_not(df_clean[\"paths\"].iloc[i]) for i in range(9)]\n",
        "images = [plt.imread(df_clean[\"paths\"].iloc[i]) for i in range(9)]\n",
        "fig, axes = plt.subplots(3, 3, figsize=(12, 10))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(images[i])\n",
        "    ax.set_title(f\"Image {i}: {'Crop' if preds[i] else 'Not crop'}\")\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bdd1H2WA-TTf"
      },
      "outputs": [],
      "source": [
        "# 20 mins for 10k images\n",
        "cropnop_run = input(\"Run CropNop model on all photos? [y/n]:\") == \"y\"\n",
        "if cropnop_run:\n",
        "    print(\"Running CropNop model on all photos\")\n",
        "    df_clean[\"is_crop\"] = df_clean[\"paths\"].progress_apply(is_crop_or_not)\n",
        "else:\n",
        "    print(\"Skipping CropNop model run\")\n",
        "    df_clean[\"is_crop\"] = True\n",
        "\n",
        "df_clean[\"is_crop\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK8Hbkesmp5o"
      },
      "source": [
        "## 5. Segment crops\n",
        "\n",
        "If there are more than 4000 crops the Colab GPU may time out. Consider going back and selecting fewer photos to process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAywn-2rApRi"
      },
      "outputs": [],
      "source": [
        "# Download CropSeg model weights\n",
        "!gsutil cp gs://street2sat-models/cropseg_v1.torchscript.pt ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4nMP3OTnYcN"
      },
      "outputs": [],
      "source": [
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "os.environ[\"LRU_CACHE_CAPACITY\"] = \"1\"\n",
        "\n",
        "# Load CropSeg model\n",
        "cropseg_model = torch.jit.load(\"/content/cropseg_v1.torchscript.pt\", map_location=device)\n",
        "\n",
        "CLASSES = [\n",
        "    \"background\",\n",
        "    \"banana\",\n",
        "    \"maize\",\n",
        "    \"rice\",\n",
        "    \"soybean\",\n",
        "    \"sugarcane\",\n",
        "    \"sunflower\",\n",
        "    \"tobacco\",\n",
        "    \"wheat\",\n",
        "]\n",
        "\n",
        "def segment_crops(img_path):\n",
        "    img = imread(img_path)\n",
        "    img = resize(img, (800, 800))\n",
        "    img = img.astype(float)\n",
        "    img = (\n",
        "        255 * (img - np.min(img[:])) / (np.max(img[:]) - np.min(img[:]) + 0.1)\n",
        "    ).astype(float)\n",
        "    img = (img + 0.5) / 256\n",
        "    gamma = -1 / np.nanmean(np.log(img))\n",
        "    img = img ** (gamma)\n",
        "    img_transposed = img.transpose(2, 0, 1).astype(\"float32\")\n",
        "    img_tensor = torch.from_numpy(img_transposed).unsqueeze(0).to(device)\n",
        "    return img, cropseg_model(img_tensor)[0].cpu().detach().numpy()\n",
        "\n",
        "\n",
        "def segment_crops_w_proportions(img_path):\n",
        "    _, output = segment_crops(img_path)\n",
        "    image_size = output.shape[1] * output.shape[2]\n",
        "    segmentation_proportions = {\n",
        "        crop:  round(output[i].sum() / image_size, 4) for i, crop in enumerate(CLASSES)\n",
        "    }\n",
        "    return segmentation_proportions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69wTYsp23Acl"
      },
      "outputs": [],
      "source": [
        "df_crops = df_clean[df_clean['is_crop']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jn-0HVDc9C3e"
      },
      "outputs": [],
      "source": [
        "n_cols = 2\n",
        "n_rows = 4\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(6, 14))\n",
        "for i in range(4):\n",
        "    img_path = df_crops[\"paths\"].iloc[i]\n",
        "    img, output = segment_crops(img_path)\n",
        "    axes[i, 0].imshow(img)\n",
        "    axes[i, 0].set_title(f\"Image {i}\")\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    segmented_img = output.argmax(axis=0)\n",
        "    axes[i, 1].imshow(segmented_img, cmap='tab10', vmin=0, vmax=len(CLASSES))\n",
        "    axes[i, 1].set_title(f\"Segmentation {i}\")\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "    props = segment_crops_w_proportions(img_path)\n",
        "    label = \"\"\n",
        "    for crop, prop in sorted(props.items(), key=lambda item: item[1], reverse=True):\n",
        "        if prop > 0.001:\n",
        "            label += (f\"{crop}: {round(prop, 4)}\\n\")\n",
        "\n",
        "    axes[i, 1].text(0.05, 0.95, label, transform=axes[i, 1].transAxes, ha='left', va=\"top\", color=\"white\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOkOJViQq1lR"
      },
      "outputs": [],
      "source": [
        "# ~10 mins for 500 images, 1hr for 2k images\n",
        "# TODO can probably make predictions faster through batches\n",
        "\n",
        "segrun = input(\"Run segmentation model? [y/n]:\").lower() == \"y\"\n",
        "if segrun:\n",
        "    print(\"Running segmentation model on all crop photos\")\n",
        "    df_crops[\"segmentation_proportions\"] = df_crops[\"paths\"].progress_apply(segment_crops_w_proportions)\n",
        "    proportion_columns = pd.json_normalize(df_crops[\"segmentation_proportions\"]).set_index(df_crops.index)\n",
        "    df_crop_prop = pd.concat([df_crops, proportion_columns], axis=1)\n",
        "    crops = list(proportion_columns.columns[1:])\n",
        "    df_crop_prop[\"dominant_crop\"] = df_crop_prop[crops].apply(lambda x: max(dict(x), key=dict(x).get), axis=1)\n",
        "else:\n",
        "    print(\"Skipping segmentation model run\")\n",
        "    df_crop_prop = df_crops\n",
        "    df_crop_prop[\"dominant_crop\"] = \"_\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7OK7kXjxpH8"
      },
      "source": [
        "## 6. Filter out low confidence predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CB0HTfPDuM_-"
      },
      "outputs": [],
      "source": [
        "if segrun:\n",
        "    # Only points with less than 95% background kept\n",
        "    bg_threshold = 0.96\n",
        "    print(f\"Before background filter: {len(df_crop_prop)}\")\n",
        "    df_crop_type = df_crop_prop[df_crop_prop[\"background\"] < bg_threshold ].copy()\n",
        "    print(f\"After background filter: {len(df_crop_type)}\")\n",
        "else:\n",
        "    df_crop_type = df_crop_prop.copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5_B17ZCGjLY"
      },
      "source": [
        "## 8. Get Admin Zones for each point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oh8W4SlKq1Jc"
      },
      "outputs": [],
      "source": [
        "geometry = [Point(xy) for xy in zip(df_crop_type[\"lon\"], df_crop_type[\"lat\"])]\n",
        "gdf_points = gpd.GeoDataFrame(df_crop_type, geometry=geometry, crs=\"EPSG:4326\")\n",
        "gdf_points_gadm2 = gpd.sjoin(gdf_points, gdf_gadm2, how='left', predicate=\"within\")\n",
        "\n",
        "df_crop_type[\"GADM1\"] = gdf_points_gadm2[\"NAME_1\"]\n",
        "df_crop_type[\"GADM2\"] = gdf_points_gadm2[\"NAME_2\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqHgbBVTtgcQ"
      },
      "outputs": [],
      "source": [
        "df_crop_type[\"GADM1\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It6A6pb2u9e7"
      },
      "outputs": [],
      "source": [
        "df_crop_type[\"GADM2\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH4t_u1SMkG0"
      },
      "source": [
        "## 9. Create KMZ file(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9F5fUCHgMv7o"
      },
      "outputs": [],
      "source": [
        "import simplekml\n",
        "\n",
        "found_admin1_zones = df_crop_type[~df_crop_type[\"GADM1\"].isna()][\"GADM1\"].unique()\n",
        "DATA_GADM1_ZONES =  \"_\".join(found_admin1_zones)\n",
        "if DATA_GADM1_ZONES not in PREFIX:\n",
        "    PREFIX += f\"_{DATA_GADM1_ZONES}\"\n",
        "\n",
        "DATA_YEARS = \"_\".join([str(year) for year in df_crop_type[\"date\"].dt.year.unique()])\n",
        "if DATA_YEARS not in PREFIX:\n",
        "    PREFIX += f\"_{DATA_YEARS}\"\n",
        "\n",
        "if segrun:\n",
        "    DATA_BG_THRESHOLD = f\"bg{int(bg_threshold*100)}\"\n",
        "    PREFIX += f\"_{DATA_BG_THRESHOLD}\"\n",
        "else:\n",
        "    PREFIX += f\"_no_segrun\"\n",
        "\n",
        "# Change if necessary\n",
        "PREFIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umpd_qNZGQkW"
      },
      "outputs": [],
      "source": [
        "def create_endpoint(image_path):\n",
        "    endpoint_suffix = str(image_path).replace(str(image_folder), \"\")\n",
        "    return GCLOUD_PATH_INPUT + endpoint_suffix\n",
        "\n",
        "def create_description(record, image_path):\n",
        "    image_name = Path(image_path).name\n",
        "    endpoint = create_endpoint(image_path)\n",
        "    a_href = \"\"\n",
        "    if GCLOUD_PATH_INPUT != \"\":\n",
        "        a_href = f\"<a href='https://storage.cloud.google.com/{endpoint}'>https://storage.cloud.google.com/{endpoint}</a>\"\n",
        "\n",
        "    segrun_proportions = \"\"\n",
        "    if segrun:\n",
        "        segrun_proportions = f\"\"\"\n",
        "<h2>CropSeg Model Prediction</h2>\n",
        "<p>{record['segmentation_proportions']}</p>\n",
        "\"\"\"\n",
        "\n",
        "    return f\"\"\"\n",
        "<img src='files/{image_name}' width='900px'/>\n",
        "<br/>\n",
        "<h2>{endpoint}</h2>\n",
        "<p>Capture Time: {record['date']}</p>\n",
        "{a_href}\n",
        "\n",
        "<h2>Location</h2>\n",
        "<p>GADM1: {record['GADM1']}</p>\n",
        "<p>GADM2: {record['GADM2']}</p>\n",
        "<p>Road Lat Lon: {record['lat']}, {record['lon']}</p>\n",
        "<p>Field Lat Lon:  {record[\"offset_field_pixel_centroid\"]}</p>\n",
        "\n",
        "\n",
        "<h2>Driving Direction</h2>\n",
        "<p>Northing: {record['driving_northing']}</p>\n",
        "<p>Easting: {record['driving_easting']}</p>\n",
        "<p>Is Right Hand Drive: {record['is_right_hand_drive']}</p>\n",
        "\n",
        "{segrun_proportions}\n",
        "\"\"\"\n",
        "if GCLOUD_PATH_INPUT != \"\":\n",
        "    print(\"Tester Link:\")\n",
        "    print(f\"https://storage.cloud.google.com/{create_endpoint(df_crop_type['paths'].iloc[0])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uULyghOYM4nR"
      },
      "outputs": [],
      "source": [
        "# Create KMZ file for every 100 points (more points make the KMZ laggy)\n",
        "num_records = len(df_crop_type)\n",
        "\n",
        "for range_start in range(0, num_records, 100):\n",
        "    if range_start + 100 < num_records:\n",
        "        range_end = range_start + 100\n",
        "    else:\n",
        "        range_end = num_records\n",
        "\n",
        "    kml_document_name = PREFIX + f\"_{range_start}_{range_end}\"\n",
        "    if \"drive/MyDrive\" not in kml_document_name:\n",
        "        kml_document_name = f\"drive/MyDrive/{kml_document_name}\"\n",
        "\n",
        "    kml = simplekml.Kml()\n",
        "    kml.document.name = kml_document_name\n",
        "\n",
        "    for _, record in tqdm(df_crop_type[range_start:range_end].iterrows()):\n",
        "        latlon = record[\"offset_field_pixel_centroid\"]\n",
        "        image_path = record['paths']\n",
        "        kml.newpoint(\n",
        "            coords=[(latlon[1], latlon[0])],  # lon, lat optional height\n",
        "            description=create_description(record, image_path),\n",
        "            name=record[\"dominant_crop\"],\n",
        "            timestamp=record[\"date\"]\n",
        "        )\n",
        "        kml.addfile(image_path)\n",
        "\n",
        "\n",
        "    kml.savekmz(f\"{kml_document_name}.kmz\", format=False)\n",
        "\n",
        "print(\"KMZ files saved to your Google Drive.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbWMG0F3XSnV"
      },
      "source": [
        "The uploaded KMZ files can now be downloaded onto a computer with Google Earth Pro.\n",
        "\n",
        "A Quality Assessment must be conducted following this protocol:\n",
        "\n",
        "https://docs.google.com/document/d/1OCF2gpCQQbZP-y6xcTbKE2OzhkxMtyaJi8wiWi8jfzs/edit?usp=sharing"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
